{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWRTETkzouUZ"
   },
   "source": [
    "## [Νικόλαος Μανιάτης](mailto:nikolaosmaniatis@mail.ntua.gr)\n",
    "## Α.Μ.: 03400097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2H70g4D1dGg"
   },
   "source": [
    "<h2><b><i>Radial Basis Function Neural Network</i></b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcUo-iIDz8xG"
   },
   "source": [
    "Σκοπός της παρούσας άσκησης είναι η κατηγοριοποίηση χειρόγραφων ψηφίων από το [MNIST dataset](https://www.wikiwand.com/en/MNIST_database) με τη χρήση νευρωνικών δικτύων [RBF](https://en.wikipedia.org/wiki/Radial_basis_function) (RBF). Για την κατηγοροποίηση των χειρόγραφων ψηφίων, χρησιμοποιείται ο αλγόριθμος K-means. Στη κλασική υλοποίηση του K-means όπου έχουμε το κέντρο του cluster και ταξινομομούμε κάθε σημείο με βάση την απόσταση από τα κέντρα. Σε αυτή την περίπτωση μπορεί να υπάρξουν σημεία που να μην μπορούν να αντιστοιχηθούν σε κάποιο cluster. Με τη χρήση του νευρωνικού δικτύου RBF κάθε σημείο ταξινομείται σε ομάδες με συγκεκριμένο κέντρο, γνωρίζοντας όμως τις αποστάσεις μεταξύ των κέντρων αλλά και με διαστήματα εμπιστοσύνης ως προς την πρόβλεψή μας. Με αυτό το τρόπο όλα τα σημεία αντιστοιχίζονται σε ένα cluster. Για να είναι ομαλή η ταξινόμηση των στοιχείων στα clusters μπορεί να χρησιμοποιηθεί μια εκθετική συνάρτηση υψωμένη στην αρνητική τιμή της απόστασης ως γινόμενο με έναν βαθμωτό συντελεστή beta, όπως φαίνεται παρακάτω:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/145/1*MIay3aIlpT18yewOfnvTiQ.png)\n",
    "\n",
    "Στα πλαίσια του παραδείγματος για το β χρησιμοποιήθηκε ο παρακάτω τύπος\n",
    "\n",
    "![alt text](https://miro.medium.com/max/608/1*YEcI_P6orY917fQrzHQEjQ.png)\n",
    "\n",
    "Όπου k ο αριθμός των clusters και Dmax η μέγιστη ευκλείδια απόσταση μεταξύ των κέντρων. Το dataset που θα χρησιμοποιήσετε είναι διαθέσιμο [εδώ](https://drive.google.com/file/d/1WrVPB3C1vIApWNz5BaSuNmHFopf5htCg/view?usp=sharing) (θα πρέπει να το φορτώσετε στο Colab για να το τρέξετε). \n",
    "\n",
    "*Οι ερωτήσεις της άσκησης είναι μαζί με το αντίστοιχο βήμα στον κώδικα*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTqNFzQsCYiP"
   },
   "source": [
    "**Βήμα 1ο**\n",
    "\n",
    "Τρέχετε τον κώδικα στον οποίο και ορίζονται οι συναρτήσεις που θα μας χρειαστούν. Στα πλαίσια της άσκησης χρησιμοποιούμε μία παραμετροποιημένη έκδοση της συνάρτησης K-Means, όπου μας επιστρέφει τα κέντρα των ομάδων (clusters) καθώς και την τυπική απόκλιση τους."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K10m9MxE98sp",
    "outputId": "fde6c5bf-d4be-466c-d229-4d1812c60219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 0 ns, total: 12 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"''\n",
    "\n",
    "Copyright © 2020 Tarlan Ahadli\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a\n",
    "copy of this software and associated documentation files (the “Software”),\n",
    "to deal in the Software without restriction, including without limitation\n",
    "the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "and/or sell copies of the Software, and to permit persons to whom the Software\n",
    "is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included\n",
    "in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY\n",
    "KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n",
    "WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE\n",
    "AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n",
    "HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n",
    "WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n",
    "OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "''\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_distance(x1, x2):\n",
    "    sum = 0\n",
    "    for i in range(len(x1)):\n",
    "        sum += (x1[i] - x2[i]) ** 2\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "\n",
    "def kmeans(X, k, max_iters):\n",
    "    centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n",
    "    # centroids = [np.random.uniform(size=len(X[0])) for i in range(k)]\n",
    "\n",
    "    converged = False\n",
    "    current_iter = 0\n",
    "\n",
    "    while (not converged) and (current_iter < max_iters):\n",
    "\n",
    "        cluster_list = [[] for i in range(len(centroids))]\n",
    "\n",
    "        for x in X:  # Go through each data point\n",
    "            distances_list = []\n",
    "            for c in centroids:\n",
    "                distances_list.append(get_distance(c, x))\n",
    "            cluster_list[int(np.argmin(distances_list))].append(x)\n",
    "\n",
    "        cluster_list = list((filter(None, cluster_list)))\n",
    "\n",
    "        prev_centroids = centroids.copy()\n",
    "\n",
    "        centroids = []\n",
    "\n",
    "        for j in range(len(cluster_list)):\n",
    "            centroids.append(np.mean(cluster_list[j], axis=0))\n",
    "\n",
    "        pattern = np.abs(np.sum(prev_centroids) - np.sum(centroids))\n",
    "\n",
    "        print('K-MEANS: ', int(pattern))\n",
    "\n",
    "        converged = (pattern == 0)\n",
    "\n",
    "        current_iter += 1\n",
    "\n",
    "    return np.array(centroids), [np.std(x) for x in cluster_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvN-O5euDlVg"
   },
   "source": [
    "**Βήμα 2ο**\n",
    "\n",
    "Τρέχουμε την κλάση για το RBFNN\n",
    "\n",
    "---\n",
    "\n",
    "***Ερώτηση 1***\n",
    "\n",
    "Να αναφέρετε επιγραμματικά με ποιον τρόπο λειτουργεί ένα νευρωνικό δίκτυο RBF.  \n",
    "***Ερώτηση 2***\n",
    "\n",
    "Στα πλαίσια του παραδείγματος, για κάθε αριθμό (κλάση) έχουμε μία μόνο ομάδα (cluster). Τι θα συνέβαινε αν είχαμε παραπάνω από μία ομάδες που θα αντιστοιχούσαν σε μία κλάση; Πώς λύνεται αυτό μέσω του RBF;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2rSgYvRrHk4"
   },
   "source": [
    "- **Ερώτηση 1**:  \n",
    "Ένα Radial Basis Function Network αποτελείται από 3 layers, το input, ένα hidden layer με μια μη γραμμική RBF activation function $h(x)$, και ένα output layer. Συγκεκριμένα, αν έχουμε ένα RBF network με $Ν$ κρυμμένους νευρώνες, ως input ένα διάνυσμα $x = (x_1,x_2,\\dots,x_d)^\\top$ μήκους $d$, και θέλουμε να υπολογίσουμε το output μήκους $p$, $y_i$ για $i=1,2,\\dots,p$, όπου $w_{ij}$ είναι το βάρος της σύνδεσης από τον κρυμμένο νευρώνα j\n",
    "προς το νευρώνα εξόδου i και $w_{i0}$ είναι το bias του νευρώνα εξόδου i: \n",
    "$$y_i(x) = w_{i0} + \\displaystyle\\sum_{i=0}^N w_{ij}h_j(x)$$\n",
    "Όπως αναφέραμε, $h(x)$ είναι η συνάρτηση πυρήνα, όπου συνήθως σε αυτές υπάρχει κάποιο σημείο (που ονομάζεται κέντρο) για το οποίο παρέχουν μέγιστη τιμή, και καθώς απομακρυνόμαστε ακτινικά από το κέντρο η τιμή της συνάρτησης μειώνεται και σχεδόν μηδενίζεται για σημεία που είναι πολύ μακριά από το κέντρο.\n",
    "Τυπικό παράδειγμα μιας τέτοιας συνάρτησης είναι ο Gaussian Kernel:\n",
    "$$ h(x) = \\exp(-\\frac{\\parallel x-w_j\\parallel^2}{2\\sigma_j^2}$$\n",
    "\n",
    "- **Ερώτηση 2**:  \n",
    "Αν είχαμε παραπάνω από ένα cluster να αντιστοιχεί σε κάθε κλάση, τότε θα μπορούσαμε να πάρουμε τον γραμμικό συνδιασμό αυτών των κλάσεων, επομένως το τελικό output που θα έβγαινε από το δίκτυο θα εξαρτάται από όλα τα RBFs. Η δυσκολία σε αυτήν την περίπτωση είναι να βρούμε τα κατάλληλα βάρη $w_{ij}$ που προσεγγίζει καλύτερα την γραμμική σχέση των πολλαπλών clusters για μια κλάση. Στα RBFs αυτό που μπορούμε να κάνουμε για να το λύσουμε αυτό είναι να χρησιμοποιήσουμε την μέθοδο της γραμμικής παλινδρόμησης με χρήση ελαχίστων τετραγώνων.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syIsRZX-Dima"
   },
   "outputs": [],
   "source": [
    "class RBF:\n",
    "\n",
    "    def __init__(self, X, y, tX, ty, num_of_classes,\n",
    "                 k, std_from_clusters=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.tX = tX\n",
    "        self.ty = ty\n",
    "\n",
    "        self.number_of_classes = num_of_classes\n",
    "        self.k = k\n",
    "        self.std_from_clusters = std_from_clusters\n",
    "\n",
    "    def convert_to_one_hot(self, x, num_of_classes):\n",
    "        arr = np.zeros((len(x), num_of_classes))\n",
    "        for i in range(len(x)):\n",
    "            c = int(x[i])\n",
    "            arr[i][c] = 1\n",
    "        return arr\n",
    "\n",
    "    def get_rbf(self, x, c, s):\n",
    "        distance = get_distance(x, c)\n",
    "        return 1 / np.exp(-distance / s ** 2)\n",
    "\n",
    "    def get_rbf_as_list(self, X, centroids, std_list):\n",
    "        RBF_list = []\n",
    "        for x in X:\n",
    "            RBF_list.append([self.get_rbf(x, c, s) for (c, s) in zip(centroids, std_list)])\n",
    "        return np.array(RBF_list)\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "      self.centroids, self.std_list = kmeans(self.X, self.k, 1000)\n",
    "\n",
    "      if not self.std_from_clusters:\n",
    "          dMax = np.max([get_distance(c1, c2) for c1 in self.centroids for c2 in self.centroids])\n",
    "          self.std_list = np.repeat(dMax / np.sqrt(2 * self.k), self.k)\n",
    "\n",
    "      RBF_X = self.get_rbf_as_list(self.X, self.centroids, self.std_list)\n",
    "\n",
    "      self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.convert_to_one_hot(self.y, self.number_of_classes)\n",
    "\n",
    "      RBF_list_tst = self.get_rbf_as_list(self.tX, self.centroids, self.std_list)\n",
    "\n",
    "      self.pred_ty = RBF_list_tst @ self.w\n",
    "\n",
    "      self.pred_ty = np.array([np.argmax(x) for x in self.pred_ty])\n",
    "\n",
    "      diff = self.pred_ty - self.ty\n",
    "\n",
    "      print('Accuracy: ', len(np.where(diff == 0)[0]) / len(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXF5VY-UD1wo"
   },
   "source": [
    "**Βήμα 3ο**\n",
    "\n",
    "Τρέχουμε τη συνάρτηση όπου το RBFNN γίνεται fit. Αρχικά τρέχει ο αλγόριθμος k-means για να βρούμε τα κέντρα και την τυπική απόκλιση των clusters. Στη συνέχεια, μπορούμε να χρησιμοποιήσουμε το ίδιο beta για όλα τα clusters\n",
    "\n",
    "\n",
    "---\n",
    "***Ερώτηση 3***\n",
    "\n",
    "Με ποιούς τρόπους μπορούμε να υπολογίσουμε τα βάρη στα hidden layers; Ποιες διαφορές υπάρχουν στους τρόπους αυτούς; Ποιος παρέχει τη καλύτερη δυνατή λύση;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Km7dT9E95fa"
   },
   "source": [
    "**Ερώτηση 3**:   \n",
    "Υπάρχουν διάφοροι τρόποι υπολογισμού των βαρών στα hidden layers, ή αλλιώς να εκπαιδεύσουμε το δίκτυο.\n",
    " - **Ενιαία εκπαίδευση δικτύου**: Χρήση Gradient Descent ή Batch Gradient Descent προς ελαχιστοποίηση της τετραγωνικής συνάρτησης σφάλματος. Συνήθως προτιμάται η Batch Gradient Descent. Εδώ είναι σημαντική η αρχικοποίηση των κέντρων και ακτίνων των RBFs καθώς μπορεί ο gradient descent να παγιδευτεί σε τοπικά ελάχιστα. Συνήθως προτιμάται η αρχικοποίηση των κεντρών των νευρώνων των RBFs να είναι το κέντρο κάποιου cluster των δεδομένων.\n",
    "\n",
    " - **Εκπαίδευση δύο σταδίων**: Εδώ στο **πρώτο στάδιο** χρησιμοποιείται το σύνολο των δεδομένων εκπαίδευσης για τον καθορισμό νευρώνων RBF, και αγνοείται η πληροφορία για το label της κλάσης. Στη συνέχεια εφαρμόζεται κάποια μέθοδος clustering π.χ. k-means ώστε να προκύψουν τα κέντρα των ομάδων, και οι ακτίνες μέσω υπολογισμού της διασποράς των δεδομένων κάθε cluster. \n",
    " Στο **δεύτερο στάδιο** έχουμε δύο επιλογές, η πρώτη είναι τα κέντρα και οι ακτίνες να παραμείνουν σταθερά, και μένει να βρεθούν τα weights και biases μόνο τυτου output layer. Στη δεύτερη περίπτωση, εφαρμόζουμε gradient descent όπως ακριβώς στην ενιαία εκπαίδευση, όμως η αρχικοποίηση των κέντρων και των ακτίνων γίνεται με τις τιμές που έχουν προκύψει από το πρώτο στάδιο. \n",
    "\n",
    " Η καλύτερη δυνατή λύση γίνεται με την εκπαίδευση δύο σταδίων, όπου χρησιμοποιείται κάποιος clustering αλγόριθμος προκειμένου να γίνει η αρχικοποίηση στα κέντρα και τις ακτίνες των ομάδων, και στην πορεία η εκπαίδευση να γίνει με batch gradient descent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWXVHJzDpZiS"
   },
   "source": [
    "**Βήμα 4ο**\n",
    "\n",
    "Σπάμε το dataset του MNIST σε training και testing και αφήνουμε το RBFNN να βγάλει το τελικό αποτέλεσμα.\n",
    "\n",
    "---\n",
    "\n",
    "***Ερώτηση 4***\n",
    "\n",
    "Επιχειρήστε να αλλάξετε την τιμή του k σε 500 και στη συνέχεια σε 1000. Τι παρατηρείτε ως προς την εκτέλεση;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuSb9i6gBge5"
   },
   "source": [
    "Τα αποτελέσματα είναι:\n",
    "- k = 10: Accuracy:  63.7%, Χρόνος εκτέλεσης: 12 min 18 sec\n",
    "- k = 500: Accuracy: 94.3%, Χρόνος εκτέλεσης: 2 hrs 19 min 44 sec\n",
    "- k = 1000: Accuracy: 95.3%, Χρόνος Εκτέλεσης: 3 hrs 24 min 32 sec\n",
    "\n",
    "Παρατηρούμε ότι για $k=10\\rightarrow k=500$ έχουμε μεγάλη αύξηση στην ακρίβεια όμως σε βάρος μεγάλου υπολογιστικού κόστους. Για $k=500\\rightarrow k=1000$ πάλι έχουμε μεγάλο υπολογιστικό κόστος για πολύ μικρή αύξηση στην ακρίβεια, επομένως κάτι τέτοιο δεν θα ήταν χρήσιμο. Είναι σημαντικό να σημειωθεί ότι μεγάλη αύξηση στους clusters είναι επικίνδυνη καθώς μπορεί να εμφανιστεί overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1xrfJvAqEC-",
    "outputId": "620f699f-6dbc-4f46-8c72-5f009218711d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#LOAD DATA\n",
    "import os \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data = np.load(os.getcwd()+'/drive/MyDrive/mnist_data.npy').astype(float)\n",
    "\n",
    "train_y = data[0:2500, 0]\n",
    "train_x = data[0:2500, 1:]\n",
    "\n",
    "# by default the code was like this:\n",
    "# test_y = data[0:300, 0]\n",
    "# test_x = data[0:300, 1:]\n",
    "#but it's wrong because we have the same samples in both train and test data (!!!)\n",
    "\n",
    "test_y = data[2500:2800,0]\n",
    "test_x = data[2500:2800,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWgAWpNVqYtO"
   },
   "source": [
    "- k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLl5UftHpkOg",
    "outputId": "d6f7d7b0-2fb6-4e56-d67c-468274e073d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-MEANS:  37174\n",
      "K-MEANS:  5385\n",
      "K-MEANS:  3947\n",
      "K-MEANS:  2726\n",
      "K-MEANS:  1987\n",
      "K-MEANS:  1203\n",
      "K-MEANS:  835\n",
      "K-MEANS:  220\n",
      "K-MEANS:  275\n",
      "K-MEANS:  234\n",
      "K-MEANS:  102\n",
      "K-MEANS:  8\n",
      "K-MEANS:  48\n",
      "K-MEANS:  3\n",
      "K-MEANS:  111\n",
      "K-MEANS:  31\n",
      "K-MEANS:  14\n",
      "K-MEANS:  13\n",
      "K-MEANS:  29\n",
      "K-MEANS:  61\n",
      "K-MEANS:  2\n",
      "K-MEANS:  43\n",
      "K-MEANS:  42\n",
      "K-MEANS:  17\n",
      "K-MEANS:  1\n",
      "K-MEANS:  8\n",
      "K-MEANS:  124\n",
      "K-MEANS:  81\n",
      "K-MEANS:  86\n",
      "K-MEANS:  36\n",
      "K-MEANS:  57\n",
      "K-MEANS:  45\n",
      "K-MEANS:  47\n",
      "K-MEANS:  23\n",
      "K-MEANS:  23\n",
      "K-MEANS:  16\n",
      "K-MEANS:  36\n",
      "K-MEANS:  39\n",
      "K-MEANS:  23\n",
      "K-MEANS:  9\n",
      "K-MEANS:  2\n",
      "K-MEANS:  64\n",
      "K-MEANS:  9\n",
      "K-MEANS:  0\n",
      "Accuracy:  0.6366666666666667\n",
      "CPU times: user 12min 16s, sys: 1.47 s, total: 12min 17s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RBF_CLASSIFIER = RBF(train_x, train_y, test_x, test_y, num_of_classes=10,\n",
    "                     k=10, std_from_clusters=False)\n",
    "\n",
    "RBF_CLASSIFIER.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2oR8q85qyT9"
   },
   "source": [
    "- k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GD4H3YDqt2e",
    "outputId": "f9f3b50d-0ecb-4982-b19b-812c085fa324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-MEANS:  414320\n",
      "K-MEANS:  415\n",
      "K-MEANS:  18407\n",
      "K-MEANS:  2248\n",
      "K-MEANS:  2019\n",
      "K-MEANS:  1169\n",
      "K-MEANS:  8\n",
      "K-MEANS:  686\n",
      "K-MEANS:  0\n",
      "Accuracy:  0.9433333333333334\n",
      "CPU times: user 2h 19min 22s, sys: 15.3 s, total: 2h 19min 37s\n",
      "Wall time: 2h 19min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RBF_CLASSIFIER = RBF(train_x, train_y, test_x, test_y, num_of_classes=10,\n",
    "                     k=500, std_from_clusters=False)\n",
    "\n",
    "RBF_CLASSIFIER.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zFFdjkHq2_J"
   },
   "source": [
    "- k = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9srg4UPq4iS",
    "outputId": "e1d027b3-65e7-4b0f-a8ca-cacce9ee2c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-MEANS:  576550\n",
      "K-MEANS:  18701\n",
      "K-MEANS:  4126\n",
      "K-MEANS:  6255\n",
      "K-MEANS:  353\n",
      "K-MEANS:  0\n",
      "Accuracy:  0.9533333333333334\n",
      "CPU times: user 3h 24min 1s, sys: 20.6 s, total: 3h 24min 22s\n",
      "Wall time: 3h 24min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RBF_CLASSIFIER = RBF(train_x, train_y, test_x, test_y, num_of_classes=10,\n",
    "                     k=1000, std_from_clusters=False)\n",
    "\n",
    "RBF_CLASSIFIER.fit()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastics_Lab9_Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
