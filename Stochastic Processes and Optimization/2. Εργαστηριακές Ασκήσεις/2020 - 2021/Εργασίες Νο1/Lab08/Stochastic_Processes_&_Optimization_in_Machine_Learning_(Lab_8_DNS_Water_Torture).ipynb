{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Νικόλαος Μανιάτης](mailto:nikolaosmaniatis@mail.ntua.gr)\n",
    "## Α.Μ.: 03400097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLUCLr2dsyWQ"
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/Lab8_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος <a href=\"https://www.ntua.gr/el/\">www.ntua.gr</a> είναι το <i>www</i>, ενώ το prefix του ονόματος <a href=\"dolly.netmode.ece.ntua.gr\">dolly.netmode.ece.ntua.gr</a> είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training</a>.txt). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Ποια είναι η παραδοχή του αλγορίθμου Naive Bayes Classifier; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;  \n",
    "\n",
    "Ο Naive Bayes Classifier κάνει δύο απλουστευτικές υποθέσεις: την ανεξαρτησία μεταξύ των χαρακτηριστικών και ότι όλα τα χαρακτηριστικά ακολουθούν την κανονική (γκαουσιανή) κατανομή.    \n",
    "Μερικά από τα πλεονεκτήματα του είναι:\n",
    "\n",
    "1. Είναι απλός αλγόριθμος με εύκολη υλοποίηση\n",
    "2. Δεν απαιτεί μεγάλο όγκο training data\n",
    "3. Μπορεί και χειρίζεται συνεχή και διακριτά δεδομένα\n",
    "4. Είναι γρήγορος και μπορεί να κάνει προβλέψεις σε πραγματικό χρόνο\n",
    "5. Δεν κάνει εύκολα overfit.\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου Naive Bayes Classifier.\n",
    "\n",
    "Δεδομένου ενός feature vector $\\vec{x} = (x_1,x_2,\\dotsc,x_n)$ και μιας μεταβλητής $y$ που μας δίνει τα class labels, από το νόμο του Bayes ισχύει:\n",
    "\n",
    "$$P(y|x_1,\\dotsc,x_n) = \\frac{P(y)P(x_1,\\dotsc,x_n | y)}{P(x_1,\\dotsc,x_n)}$$ \n",
    "λόγω της παραδοχής ανεξαρτησίας των χαρακτηριστικών:\n",
    "$$ P(x_i|y,x_1,\\dotsc,x_{i-1},x_{i+1},\\dotsc,x_n) = P(x_i,y)$$\n",
    "$\\forall i $, η αρχική σχέση γίνεται:\n",
    "$$P(y|x_1,\\dotsc,x_n) = \\frac{P(y)\\displaystyle\\prod_{i=0}^nP(x_i| y)}{P(x_1,\\dotsc,x_n)} $$ \n",
    "Εφόσον ο παρονομαστής είναι σταθερός καθώς εξαρτάται από όλο το input, μπορούμε να χρησιμοποιήσουμε τα παρακάτω ως κανόνα ταξινόμησης:\n",
    "\n",
    "$$ P(y|x_1,\\dotsc,x_n) \\propto P(y)\\displaystyle\\prod_{i=0}^nP(x_i| y)$$ \n",
    "και χρησιμοποιώντας την εκτίμηση Maximum A Posteriori (MAP) μπορούμε να υπολογίσουμε το $P(y)$ και το $P(x_i| y)$, επομένως η πρόβλεψη γίνεται παίρνοντας την πιθανότερη κλάση $\\hat{y}$ που δίνεται από τη σχέση: \n",
    "$$ \\hat{y} = \\arg\\max_{y} P(y)\\displaystyle\\prod_{i=0}^nP(x_i| y)$$ \n",
    "Στην περίπτωσή μας όπου ο ταξινομητής είναι Bayesian, το $P(x_i| y)$ δίνεται από την γνωστή σχέση: \n",
    "$$ P\\left(x_{i} \\mid y\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{y}^{2}}} \\exp \\left(-\\frac{\\left(x_{i}-\\mu_{y}\\right)^{2}}{2 \\sigma_{y}^{2}}\\right)$$\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - > Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία `valid_training.txt` και `invalid_training.txt`. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων\n",
    " \n",
    "Παρατηρούμε ότι τα prefixes των `valid_training.txt` είναι ονόματα DNS τα οποία κατά πλειοψηφία αντιστοιχούν σε λέξεις οι οποίες είναι κατανοητές από έναν άνθρωπο, είναι λιγότερο τυχαία και έχουν κατά μέσο όρο μικρότερο μήκος από ότι τα invalid.Ενδεχομένως κάποια από αυτά τα prefixes ή κομμάτια τους να αντιστοιχούν και σε λέξεις που θα βρει κάποιος σε ένα λεξικό.\n",
    "\n",
    "Αντιθέτως, τα prefixes των `invalid_training.txt` φαίνονται τυχαία και computer generated, χρησιμοποιούν περισσότερα σύμβολα και αριθμους καθώς και συνδιασμών τους, που αυτά προκύπτουν σε prefixes τα οποία δεν είναι αναγνώσιμα καθώς δεν αντιστοιχούν σε λέξεις. Επίσης έχουν μεγαλύτερο μήκος κατά μέσο όρο.\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - > Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;\n",
    "\n",
    "Τα 7 features που χρησιμοποιούνται είναι:\n",
    "`total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence`\n",
    "δηλαδή: το μήκος του prefix, τα συνολικά ψηφία στο prefix, η μέγιστη ακολουθία με ψηφία, τον συνολικό αριθμό συμφώνων, την μέγιστη ακολουθία από σύμφωνα και τα συνολικά φωνήεντα.\n",
    " \n",
    " <hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - > Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο test set για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του training set; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;\n",
    " \n",
    "O αλγόριθμος έχει missclassification rate 1.92\\% για τα valid names και 1.27\\% για τα invalid. Όσον αφορά το μέγεθος του training set, εκτελώντας `len(valid_names_training) + len(invalid_names_training)` παίρνουμε 1.400.000 prefixes. Η εκπαίδευση του αλγόριθμου, με χρήση της εντολής `%%time`, διήρκησε 14 δευτερόλεπτα.\n",
    " \n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - >  Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: problematic_valid.txt και problematic_invalid.txt. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου Naive Bayes Classifier. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf);\n",
    " \n",
    "Τα prefixes σε αυτά τα αρχεία, δημιουργούν πρόβλημα διότι ο αλγόριθμος τα συναντάει στο test set ενώ δεν τα έχει ξαναδεί στο train, επομένως τους προσδίδει μηδενική posterior πιθανότητα. Αυτό είναι γνωστό ως zero-frequency problem. Για να λύσουμε αυτό το πρόβλημα, θα μπορούσαμε να εφαρμόσουμε μια smoothing τεχνική όπως π.χ. η laplace smoothing όπου προσδίδεται μια posterior πιθανότητα σε όλα τα δείγματα, αντιστρόφως ανάλογη του πλήθους των δειγμάτων.\n",
    " <hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Μελετώντας τη συνάρτηση find_prob(), θα δείτε πως λείπουν οι πιθανότητες prior από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις prior πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (valid, invalid) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;\n",
    "\n",
    "Η παραδοχή που έχει γίνει είναι ότι οι prior πιθανότητες είναι ίσες, δηλαδή 0.5 και 0.5 αντίστοιχα για τα valid και invalid. Θα μπορούσαμε να εκτιμήσουμε τις prior πιθανότητες από εκτιμήτρια MLE, υπολογίζοντας τις σχετικές συχνότητες των valid και invalid κατηγοριών στα δεδομένα μας. Άλλος ένας τρόπος είναι με Bayesian MAP.\n",
    "\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > Μπορείτε να προτείνετε κάποιο επιπρόσθετο feature για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)\n",
    "\n",
    "Ένα επιπρόσθετο feature του αλγόριθμου θα ήταν οι valid λέξεις να αναζητούνται σε κάποιο λεξικό ή μέσω κάποιας NLP τεχνικής να εντοπίζεται αν είναι πραγματικές λέξεις ή αυτές οι λέξεις δεν υπάρχουν. Για παράδειγμα το εργαλείο [ekphrasis](https://github.com/cbaziotis/ekphrasis).\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_plJQ1Z2i5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n",
      "CPU times: user 15.1 s, sys: 59.9 ms, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)    \n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "            \n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\") \n",
    "\n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "\n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_8_DNS_Water_Torture).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
