{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLUCLr2dsyWQ"
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/Lab_theory\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος www.ntua.gr είναι το <i>www</i>, ενώ το prefix του ονόματος dolly.netmode.ece.ntua.gr είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Απαντήσεις\n",
    "\n",
    "- <font color='#486393'>Η πολύ σημαντική παραδοχή που υιοθετεί ο Ταξινομητής Naive Bayes είναι πως τα χαρακτηριστικά (features) είναι μεταξύ τους ανεξάρτητα. Έτσι, η πιθανοφάνεια ενός δειγματικού σημείου $\\mathbf{x} = \\left[x_1,x_2,\\dots,x_m\\right]^\\top$ και της αντίστοιχης εξόδου, $y$, μπορεί να γραφεί ως</font>\n",
    "\n",
    "<font color='#486393'>$$p\\left(\\mathbf{x}|y\\right) = \\prod_{k=1}^{m}{p\\left(x_k|y\\right)}.$$</font>\n",
    "    \n",
    "<font color='#486393'>Σε ό,τι έχει να κάνει με προτερήματα του αλγορίθμου, η υλοποίησή του είναι αρκετά απλή, ενώ η εκτέλεσή του αρκετά γρήγορη. Επιπλέον, σε περιπτώσεις όπου η υπόθεση περί ανεξαρτησίας είναι όσο το δυνατό πιο ρεαλιστική, ο αλγόριθμος είναι πιο αποτελεσματικός σε σχέση με άλλους, ακόμα και πιο σύνθετους, και απαιτεί για την εκπαίδευση του ταξινομητή λιγότερα δεδομένα εκπαίδευσης. Πρόσθετα, μπορεί να διαχειριστεί κάθε είδος δεδομένου: από κατηγορικά μέχρι αριθμητικά και από συνεχή μέχρι διακριτά. Τέλος, δεν είναι ευαίσθητος σε χαρακτηριστικά τα οποία μπορεί να αποδειχτούν λιγότερο χρήσιμα για την ταξινόμηση των δειγμάτων και ως εκ τούτου δεν κάνει εύκολα υπερπροσαρμογή (overfit) στα δεδομένα.</font>\n",
    "\n",
    "- <font color='#486393'>Θεωρώντας ένα πρόβλημα ταξινόμησης, το ζητούμενο είναι η εύρεση της κατηγορίας, $y$, στην οποία ανήκει ένα δειγματικό σημείο, $\\mathbf{x} = \\left[x_1,x_2,\\dots,x_m\\right]^\\top$. Δεδομένης της προαναφερθείσας ανεξαρτησίας των χαρακτηριστικών, ο νόμος του Bayes για την posterior πιθανότητα $p\\left(y|\\mathbf{x}\\right)$ παίρνει τη μορφή</font>\n",
    "\n",
    "<font color='#486393'>$$p\\left(y|\\mathbf{x}\\right) = \\frac{p\\left(\\mathbf{x}|y\\right)p\\left(y\\right)}{p\\left(\\mathbf{x}\\right)} = \\frac{p\\left(y\\right)}{p\\left(\\mathbf{x}\\right)}\\prod_{k=1}^{m}{p\\left(x_k|y\\right)}.$$</font>\n",
    "\n",
    "<font color='#486393'>Ο παρανομαστής στο τελευταίο σκέλος είναι ανεξάρτητος του $y$, συνεπώς για την ταξινόμηση ενός δειγματικού σημείου αρκεί κανείς να χρησιμοποιήσει μόνο τον αριθμητή:</font>\n",
    "\n",
    "<font color='#486393'>$$p\\left(y|\\mathbf{x}\\right) \\propto p\\left(y\\right)\\prod_{k=1}^{m}{p\\left(x_k|y\\right)}.$$</font>\n",
    "\n",
    "<font color='#486393'>Δεδομένης της ποσότητας αυτής, η πρόβλεψη του ταξινομητή για την κλάση στην οποία ανήκει το δειγματικό σημείο γίνεται βάσει του κανόνα απόφασης Maximum A Posteriori (MAP), δηλαδή την επιλογή εκείνης της τιμής του $y$ που μεγιστοποιεί την posterior πιθανότητα (η πιο πιθανή υπόθεση):</font>\n",
    "\n",
    "<font color='#486393'>$$ \\hat{y} = \\text{argmax}_{y}\\left[ p\\left(y\\right)\\prod_{k=1}^{m}p\\left(x_k|y\\right)\\right].$$</font>\n",
    "\n",
    "- <font color='#486393'>Σε ό,τι αφορά το αρχείο `valid_training.txt`, αυτό περιλαμβάνει συμβολοσειρές οι οποίες ως επί το πλείστον αντιστοιχούν σε λέξεις, φράσεις ή συντομογραφίες, οι οποίες είναι κατανοητές από έναν άνθρωπο και άρα θα μπορούσαν να αντιστοιχούν σε πραγματικά ονόματα ιστοσελιδών. Από την άλλη, τα περιεχόμενα του αρχείου `invalid_training.txt` δεν αντιστοιχούν σε λέξεις ή έννοιες κατανοητές από έναν άνθρωπο, παρά θυμίζουν περισσότερο τυχαίες συμβολοσειρές.</font>\n",
    "\n",
    "<font color='#486393'>Πέραν των νοηματικών αυτών διαφορών, μια ακόμη σημαντική διαφορά ανάμεσα στο περιεχόμενο των δύο αρχείων έγκειται στο μέσο μήκος των συμβολοσειρών. Όπως φαίνεται από το επόμενο κελί, το μέσο μήκος συμβολοσειράς για το αρχείο `valid_training.txt` είναι 10, ενώ το αντίστοιχο μέσο μήκος για το αρχείο `invalid_training.txt` είναι 20.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το μέσο μήκος συμβολοσειράς για το αρχείο valid_training.txt είναι 10.\n",
      "Το μέσο μήκος συμβολοσειράς για το αρχείο invalid_training.txt είναι 20.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "valid_train = pd.read_csv('valid_training.txt', header=None)\n",
    "invalid_train = pd.read_csv('invalid_training.txt', header=None)\n",
    "\n",
    "mean_v_l = int(valid_train[0].str.len().mean())\n",
    "mean_inv_l = int(invalid_train[0].str.len().mean())\n",
    "\n",
    "print(f'Το μέσο μήκος συμβολοσειράς για το αρχείο valid_training.txt είναι {mean_v_l}.')\n",
    "print(f'Το μέσο μήκος συμβολοσειράς για το αρχείο invalid_training.txt είναι {mean_inv_l}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color='#486393'>Τα 7 χαρακτηριστικά που χρησιμοποιούνται για τον κώδικα του παρόντος notebook είναι:</font>\n",
    "\n",
    "<font color='#486393'>`total_length`: το μήκος της συμβολοσειράς</font>\n",
    "\n",
    "<font color='#486393'>`total_digits`: το σύνολο των χαρακτήρων της συμβολοσειράς που αντιστοιχούν σε ψηφία </font>\n",
    "\n",
    "<font color='#486393'>`max_numeric_sequence`: το μέγιστο πλήθος ψηφίων που εμφανίζονται σε κάποια συμβολοσειρά του δείγματος</font>\n",
    "\n",
    "<font color='#486393'>`total_consonants`: το σύνολο των συμφώνων της συμβολοσειράς</font>\n",
    "\n",
    "<font color='#486393'>`max_consonants_sequence`: το μέγιστο πλήθος συμφώνων που εμφανίζονται σε κάποια συμβολοσειρά του δείγματος</font>\n",
    "\n",
    "<font color='#486393'>`total_vowels`: το σύνολο των φωνηέντων της συμβολοσειράς</font>\n",
    "\n",
    "<font color='#486393'>`max_vowels_sequence`: το μέγιστο πλήθος φωνηέντων που εμφανίζονται σε κάποια συμβολοσειρά του δείγματος</font>\n",
    "\n",
    "- <font color='#486393'>Τρέχοντας τον κώδικα που παρατίθεται στο παρόν notebook και χρησιμοποιώντας την εντολή `%%time`, φαίνεται πως ο συνολικός απαιτούμενος χρόνος είναι 18.3 δευτερόλεπτα (Wall time και όχι CPU time) σε μηχάνημα με επεξεργαστή i7-10700KF CPU @ 3.80 GHz.</font>\n",
    "\n",
    "<font color='#486393'>Το ποσοστό λανθασμένων ταξινομήσεων για τα περιεχόμενα του αρχείου `valid_training.txt` ήταν περίπου 1.92%, ενώ το ποσοστό λανθασμένων ταξινομήσεων για τα περιεχόμενα του αρχείου `invalid_training.txt` ήταν περίπου 1.27%. Φαίνεται, λοιπόν, πως ο αλγόριθμος έχει σε γενικές γραμμές αρκετά υψηλή απόδοση, αν και είναι λίγο πιο επιρρεπής (σχετικά πάντα) στο να ταξινομεί δειγματικά σημεία ως invalid (γι' αυτό και το ποσοστό ταξινομήσεων valid δεδομένων ως invalid είναι μεγαλύτερο από το ποσοστό ταξινομήσεων invalid δεδομένων ως valid).</font>\n",
    "\n",
    "<font color='#486393'>Τέλος, σε ό,τι έχει να κάνει με το μέγεθος του δείγματος εκμάθησης, αυτό αντιστοιχεί σε 1.400.000 συμβολοσειρές, όπως φαίνεται και από το ακόλουθο κελί.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το συνολικό μέγεθος του training set είναι 1400000 συμβολοσειρές.\n"
     ]
    }
   ],
   "source": [
    "print(f'Το συνολικό μέγεθος του training set είναι {len(valid_train)+len(invalid_train)} συμβολοσειρές.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color='#486393'>Ο ρόλος των δύο αυτών αρχείων είναι η καταγραφή των συμβολοσειρών οι οποίες δημιουργούν το πρόβλημα που είναι γνωστό ως <i>zero frequency problem</i> (πρόβλημα μηδενικής συχνότητας) κατά τη χρήση του ταξινομητή Naive Bayes. Συγκεκριμένα, το πρόβλημα αυτό προκύπτει όταν ο αλγόριθμος καλείται να ταξινομήσει ένα δείγμα που δεν έχει συναντήσει κατά την εκπαίδευσή του σε μια από τις κατηγορίες και για το λόγο αυτό του προσδίδει μηδενική posterior πιθανότητα στην κατηγορία αυτή. Έτσι, ακόμη κι αν η posterior πιθανότητά του στην άλλη κατηγορία είναι πάρα πολύ μικρή, τελικά θα ταξινομηθεί (εσφαλμένα) σε αυτήν. Μία πιθανή λύση στο πρόβλημα αυτό είναι το λεγόμενο additive smoothing (γνωστό και ως Laplace smoothing), κατά το οποίο προστίθεται ένας αριθμός στην τελική posterior πιθανότητα όλων των δειγμάτων, ο οποίος είναι αντιστρόφως ανάλογος του πλήθους τους. Η διαδικασία αυτή έχει ορισμένες αναλογίες με την πρόσθεση πολύ μικρών αριθμών, π.χ. $10^{-10}$, σε αριθμούς που βρίσκονται σε παρανομαστές κλασμάτων, προκειμένου να εξασφαλίσουμε overflow errors σε υπολογισμούς που πραγματοποιεί μια μηχανή.</font>\n",
    "\n",
    "- <font color='#486393'>Η παραδοχή που έχει γίνει εδώ είναι πως οι prior πιθανότητες είναι ίσες (0.5 έκαστη), το οποίο είναι μια εύλογη παραδοχή από τη στιγμή που το μέγεθος των δύο συνόλων εκπαίδευσης (ένα για valid και ένα για invalid) είναι κοινό (700.000 συμβολοσειρές έκαστο). Υπάρχουν διάφορες εναλλακτικές για την εκτίμηση των prior πιθανοτήτων, μέσω αλγορίθμων που εκτιμούν γενικά παραμέτρους στατιστικών κατανομών, δεδομένου ενός δειγματικού συνόλου. Ο γνωστότερος εξ αυτών είναι μάλλον ο αλγόριθμος Maximum Likelihood Estimation (MLE).</font>\n",
    "\n",
    "- <font color='#486393'>Με βάση τα χαρακτηριστικά που έχουν επιλεχθεί, για κάθε συμβολοσειρά που ανήκει στο δείγμα, υπολογίζεται το πλήθος των συμφώνων, των φωνηέντων και των ψηφίων που αυτή περιλαμβάνει. Πέραν αυτού όμως, θα μπορούσαν να κατασκευαστούν χαρακτηριστικά τα οποία να λαμβάνουν υπ' όψιν και τις σχετικές τους θέσεις κατά μήκος της συμβολοσειράς. Για παράδειγμα, μια συμβολοσειρά που περιλαμβάνει πολλά φωνήεντα ή σύμφωνα συνεχόμενα, ή που τα ψηφία της δεν είναι αυστηρά εντοπισμένα σε κάποια περιοχή της, αλλά εκτείνονται τυχαία κατά μήκος της, είναι αρκετά πιθανό να αντιστοιχεί σε invalid δεδομένο.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O_plJQ1Z2i5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)    \n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "            \n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\") \n",
    "\n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "\n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_10_DNS_Water_Torture).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
